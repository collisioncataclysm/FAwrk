{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import library and API key"
      ],
      "metadata": {
        "id": "hdYWPR3xmp2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get('sectors_api')"
      ],
      "metadata": {
        "id": "SBWegDy8EfJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib import rcParams\n",
        "from datetime import timedelta\n",
        "import datetime\n",
        "\n",
        "import statsmodels.api as sm"
      ],
      "metadata": {
        "id": "mbhkDBX_KJg3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function"
      ],
      "metadata": {
        "id": "-TSqxBN0CN4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create list of date function\n",
        "def get_date_list(start_date):\n",
        "    start_date = datetime.datetime.strptime(start_date, '%Y-%m-%d')\n",
        "\n",
        "    end_date = datetime.datetime.today()\n",
        "\n",
        "    date_list = []\n",
        "\n",
        "    while start_date < end_date:\n",
        "        date_list.append(start_date)\n",
        "        start_date += timedelta(days=90)\n",
        "\n",
        "    date_list.append(end_date)\n",
        "\n",
        "    return date_list"
      ],
      "metadata": {
        "id": "CHRoKfcEGW_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Correlation Analysis"
      ],
      "metadata": {
        "id": "xdXz1E_NDXw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sector's Market Cap data Fetching\n",
        "def fetch_sectors_market_cap(sector_list):\n",
        "  # Initiate empty data frame\n",
        "  df_sec = pd.DataFrame()\n",
        "\n",
        "  # Iterate through all stock name\n",
        "  for i in sector_list:\n",
        "      # Replace the URL with a URL from the Available Endpoints section\n",
        "      url = f\"https://api.sectors.app/v1/sector/report/{i}/?sections=market_cap\"\n",
        "\n",
        "      headers = {\n",
        "          \"Authorization\": api_key\n",
        "      }\n",
        "\n",
        "      response = requests.get(url, headers = headers)\n",
        "\n",
        "      if response.status_code == 200:\n",
        "          data = response.json()\n",
        "      else:\n",
        "          # Handle error\n",
        "          print(response.status_code)\n",
        "\n",
        "      # Data manipulation\n",
        "      df_mcap = pd.DataFrame(pd.DataFrame(data).T[\"quarterly_market_cap\"]).T\n",
        "\n",
        "      df_mcap = pd.json_normalize(df_mcap[\"market_cap\"][0]).T.reset_index()\n",
        "      df_mcap.columns = [\"measurement\",\"value\"]\n",
        "      df_mcap[['measurement', 'year','quarter']] = df_mcap['measurement'].str.split('.', expand=True)\n",
        "      df_mcap[\"sector\"] = i\n",
        "\n",
        "      # Combine new fetched data with existing data\n",
        "      df_sec = pd.concat([df_sec,df_mcap])\n",
        "\n",
        "  return(df_sec)"
      ],
      "metadata": {
        "id": "12zFF8RGCPuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleansing\n",
        "def sectors_market_cap_data_cleansing(df_sec):\n",
        "  #Convert long table to wide table\n",
        "  df_sec_pivot = df_sec.pivot(index=[\"measurement\",\"year\",\"quarter\"],columns=\"sector\",values=\"value\").reset_index()\n",
        "\n",
        "  # Remove 'current_ttm_mcap_pavg' from measurement column\n",
        "  df_sec_pivot = df_sec_pivot[df_sec_pivot.measurement != 'current_ttm_mcap_pavg']\n",
        "\n",
        "  return(df_sec_pivot)"
      ],
      "metadata": {
        "id": "QuStm-WoDnSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Historical plot\n",
        "def historical_mc_plot(df_sec):\n",
        "  # Use the same sector data\n",
        "  df_sec_lags = df_sec.copy()\n",
        "\n",
        "  # Data Manipulation\n",
        "  df_sec_lags['date'] = pd.to_datetime(df_sec['year'].astype(str) + '-' + df_sec['quarter'])\n",
        "  df_sec_lags = df_sec_lags.rename(columns={\"value\":\"mcap\"})\n",
        "  df_sec_lags = df_sec_lags[df_sec_lags.measurement != \"current_ttm_mcap_pavg\"].sort_values([\"sector\",\"year\",\"quarter\"])\n",
        "\n",
        "  # Create the line chart\n",
        "  plt.figure(figsize=(12, 6))\n",
        "  for sector in df_sec_lags['sector'].unique():\n",
        "      plt.plot(df_sec_lags[df_sec_lags['sector'] == sector]['date'],\n",
        "              df_sec_lags[df_sec_lags['sector'] == sector]['mcap'],\n",
        "              marker='o',\n",
        "              label=sector)\n",
        "\n",
        "  plt.xlabel('Quarter')\n",
        "  plt.ylabel('Market Cap Value')\n",
        "  plt.title('Market Cap Value of Sectors Over Quarters and Years')\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "coHmeCDuFO2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lag Correlation between Sectors\n",
        "def lag_correlation_sectors(df_sec_cleaned):\n",
        "  # Create date column using year and quarter column\n",
        "  df_sec_cleaned['date'] = pd.to_datetime(df_sec_cleaned['year'].astype(str) + '-' + df_sec_cleaned['quarter'])\n",
        "\n",
        "  # Make a copy dataframe so it will not overwrite the original data\n",
        "  df_sec_shifted = df_sec_cleaned.copy()\n",
        "\n",
        "  # Shift data\n",
        "  for i in ['banks', 'basic-materials','food-beverage', 'oil-gas-coal', 'telecommunication', 'utilities']:\n",
        "    df_sec_shifted[f'{i}_shifted_2'] = df_sec_shifted[i].shift(2)\n",
        "\n",
        "  # Calculate correlation\n",
        "  corr_matrix = df_sec_shifted.drop(['measurement', 'year', 'quarter','date'],axis = 1).corr()\n",
        "  corr_matrix_filtered = corr_matrix.reset_index()[corr_matrix.reset_index().sector.isin(['banks', 'basic-materials','food-beverage', 'oil-gas-coal', 'telecommunication', 'utilities'])]\n",
        "  corr_matrix_filtered.set_index(\"sector\",inplace=True)\n",
        "\n",
        "  # Plot the heatmap\n",
        "  plt.figure(figsize=(30, 12))\n",
        "  sns.heatmap(corr_matrix_filtered.drop(['banks', 'basic-materials','food-beverage', 'oil-gas-coal', 'telecommunication', 'utilities'],axis=1), annot=True, cmap=plt.cm.RdBu, vmin=-1, vmax=1)\n",
        "  plt.title('Correlation Matrix')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "szr-yoL4Fo-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_top_companies_per_sector(date,stock_list):\n",
        "  df_daily_hist = pd.DataFrame()\n",
        "\n",
        "  for i in stock_list:\n",
        "    for j in range (0,len(date)-1):\n",
        "        if j==0:\n",
        "            start_date = date[j]\n",
        "            start_date = start_date.strftime('%Y-%m-%d')\n",
        "\n",
        "            end_date = date[j+1]\n",
        "            end_date = end_date.strftime('%Y-%m-%d')\n",
        "        else:\n",
        "            start_date = date[j]+ timedelta(days=1)\n",
        "            start_date = start_date.strftime('%Y-%m-%d')\n",
        "\n",
        "            end_date = date[j+1]\n",
        "            end_date = end_date.strftime('%Y-%m-%d')\n",
        "\n",
        "        url = f\"https://api.sectors.app/v1/daily/{i}/?start={start_date}&end={end_date}\"\n",
        "\n",
        "\n",
        "        headers = {\n",
        "            \"Authorization\": api_key\n",
        "        }\n",
        "\n",
        "        response = requests.get(url, headers = headers)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            data = response.json()\n",
        "            df_daily_hist = pd.concat([df_daily_hist,pd.DataFrame(data)])\n",
        "\n",
        "  return df_daily_hist"
      ],
      "metadata": {
        "id": "FwLq2UNMIWAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_companies_data_clean_correlation(df_daily_hist):\n",
        "  # Date type manipulation\n",
        "  df_daily_hist[\"date\"] = pd.to_datetime(df_daily_hist[\"date\"])\n",
        "  df_daily_hist[\"month\"] = df_daily_hist[\"date\"].dt.month\n",
        "  df_daily_hist[\"year\"] = df_daily_hist[\"date\"].dt.year\n",
        "\n",
        "  df_daily_hist[\"close_shift_6_months\"] = df_daily_hist.groupby(\"symbol\")[\"close\"].shift(180)\n",
        "\n",
        "  return(df_daily_hist)"
      ],
      "metadata": {
        "id": "MW6qq6GlYBrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seasonality"
      ],
      "metadata": {
        "id": "wEexFgn3Y4yF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_2_companies_per_sectors(sector_list):\n",
        "  # Initiate empty data frame\n",
        "  df_top_2_comp = pd.DataFrame()\n",
        "\n",
        "  # Iterate through all stock name\n",
        "  for i in sector_list:\n",
        "      url = f\"https://api.sectors.app/v1/sector/report/{i}/?sections=companies\"\n",
        "\n",
        "\n",
        "      headers = {\n",
        "          \"Authorization\": api_key\n",
        "      }\n",
        "\n",
        "      response = requests.get(url, headers = headers)\n",
        "\n",
        "      if response.status_code == 200:\n",
        "          data = response.json()\n",
        "      else:\n",
        "          # Handle error\n",
        "          print(response.status_code)\n",
        "\n",
        "      # Data Manipulation\n",
        "      df_company = pd.json_normalize(pd.json_normalize(pd.DataFrame(pd.DataFrame(data).T[\"top_companies\"]).T[\"companies\"][0])[\"top_mcap\"][0])\n",
        "      df_company['sub_sector'] = i\n",
        "\n",
        "      # Combine new sector fetched with existing data\n",
        "      df_top_2_comp = pd.concat([df_top_2_comp,df_company])\n",
        "\n",
        "  # Take two largest company per sub-sector\n",
        "  df_top_2_comp = df_top_2_comp.groupby('sub_sector').apply(lambda x: x.nlargest(2, 'market_cap')).drop(\"sub_sector\",axis=1).reset_index().drop(\"level_1\",axis=1)\n",
        "\n",
        "  return df_top_2_comp"
      ],
      "metadata": {
        "id": "ENjw3BCWY6ha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def seasonality_daily_price_cleansing(df_daily_hist):\n",
        "  # Merge daily data and top companies data to get the subsector for each companies\n",
        "  df_daily_hist = df_daily_hist.merge(df_top_2_comp[[\"sub_sector\",\"symbol\"]], on = \"symbol\")\n",
        "\n",
        "  # Make a new column to combine the symbol and subsector\n",
        "  df_daily_hist[\"symbol_sub_sec\"] = df_daily_hist[\"symbol\"] + \"_\" + df_daily_hist[\"sub_sector\"]\n",
        "\n",
        "  # Create long data to wide data\n",
        "  df_daily_hist = df_daily_hist.pivot(index=[\"date\"],columns=\"symbol_sub_sec\",values=\"close\").reset_index()\n",
        "\n",
        "  # Drop columns with null value more than 50% of the data\n",
        "  df_daily_hist = df_daily_hist.dropna(thresh=df_daily_hist.shape[0]*0.5,axis=1)\n",
        "\n",
        "  return df_daily_hist"
      ],
      "metadata": {
        "id": "M7U9q2ObcdAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sectors Correlation Analysis"
      ],
      "metadata": {
        "id": "jj4XuSVIB1tz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Market Capitalization Correlation"
      ],
      "metadata": {
        "id": "4DdZyncTKCYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data from API\n",
        "stock_list = [\"banks\",\"basic-materials\",\"oil-gas-coal\",\"utilities\",'food-beverage','telecommunication']\n"
      ],
      "metadata": {
        "id": "3U-AAPztCfV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read data from file\n",
        "df_sec = pd.read_csv(\"/content/sectors_marketcap.csv\")"
      ],
      "metadata": {
        "id": "hkEFnth4223B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show data\n"
      ],
      "metadata": {
        "id": "_m0icriEC-LX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sectors Market Cap Data Cleansing and Processing\n"
      ],
      "metadata": {
        "id": "aCmmN0PvtZb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop some variables and calculate correlation\n",
        "\n",
        "\n",
        "# Plot the heatmap\n"
      ],
      "metadata": {
        "id": "3AGn92kYKYNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lags Correlation"
      ],
      "metadata": {
        "id": "ZRkD8G7_KaQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Sectors to Sectors Lag Correlation"
      ],
      "metadata": {
        "id": "kf2gDrHSLJY6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Historical Sectors's Market Capitalization Line Plot\n"
      ],
      "metadata": {
        "id": "SeNEwWIKKebn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lag Correlation Between Sectors\n"
      ],
      "metadata": {
        "id": "FyLixnaJK4VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Take Companies From the Highest Correlation Sector"
      ],
      "metadata": {
        "id": "hwLv2DFmLpk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch Top Companies Daily data\n",
        "stock_list = ['BYAN', 'DSSA.JK', 'CUAN.JK', 'ADRO.JK', 'ADMR.JK','PGEO.JK','POWR.JK','KEEN.JK','ARKO.JK']\n",
        "\n",
        "date = get_date_list(\"2019-01-01\")\n",
        "\n"
      ],
      "metadata": {
        "id": "f6IPJimfLZb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Top Company Correlation Fata Data Cleansing and Processing\n"
      ],
      "metadata": {
        "id": "VspnWQ1kYZXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####2023"
      ],
      "metadata": {
        "id": "NQ5UiCoAxvXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Correlation between Companies for year 2023\n",
        "df_daily_hist_2023 = df_daily_hist[df_daily_hist.year==2023]\n",
        "df_daily_hist_2023 = df_daily_hist_2023.pivot(index=\"date\",columns=\"symbol\",values=[\"close\",\"close_shift_6_months\"])\n",
        "df_daily_hist_2023_corr = df_daily_hist_2023.corr().dropna(how='all').dropna(how='all',axis=1)\n",
        "df_daily_hist_2023_corr.loc[[('close_shift_6_months',\"ARKO.JK\"),('close_shift_6_months',\"POWR.JK\"),('close_shift_6_months',\"KEEN.JK\"),('close_shift_6_months',\"PGEO.JK\")],[('close',\"ADRO.JK\"),('close',\"BYAN.JK\"),('close',\"DSSA.JK\"),('close',\"ADMR.JK\"),('close',\"CUAN.JK\")]]"
      ],
      "metadata": {
        "id": "YltX9jk7wF3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2024"
      ],
      "metadata": {
        "id": "4rqvAj6FwEJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Correlation between Companies for year 2024\n"
      ],
      "metadata": {
        "id": "14evXeBXXoUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Seasonality Analysis"
      ],
      "metadata": {
        "id": "Jzbz44TwB8Yn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get 2 Top Companies by Market Cap per Sectors"
      ],
      "metadata": {
        "id": "2AJIcfnKf9vJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify what stock to be analyzed\n",
        "sector_list = [\"banks\",\"basic-materials\",\"oil-gas-coal\",\"utilities\"]\n",
        "\n",
        "# Fetch 2 Top 2 Companies in each Sectors\n"
      ],
      "metadata": {
        "id": "MEwDB3C6f8uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Data\n",
        "df_top_2_comp = pd.read_csv(\"/content/top_2_companies.csv\")"
      ],
      "metadata": {
        "id": "-VmllvMy_1W6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show data\n",
        "df_top_2_comp"
      ],
      "metadata": {
        "id": "DQzn7syiAGdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Historical Close Price"
      ],
      "metadata": {
        "id": "3gB8e-dxgaNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch historical daily transaction data\n",
        "date = get_date_list(\"2019-01-01\")\n",
        "\n"
      ],
      "metadata": {
        "id": "PGiNCc4HMMep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read Data\n",
        "df_daily = pd.read_csv(\"/content/stocks_daily_data.csv\")"
      ],
      "metadata": {
        "id": "kaqea9osAO3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seasonality Daily Data Cleansing & Processing\n"
      ],
      "metadata": {
        "id": "uD82AEZPc5-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot Historical Close Price of some Major Companies in Indonesia\n"
      ],
      "metadata": {
        "id": "EhnSMUMwet0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seasonality Decompose"
      ],
      "metadata": {
        "id": "N10n1kcQuhuu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Every time series data, has 3 components to create a value\n",
        "\n",
        "y = Trend + Seasonality + Residual (Additive)\n",
        "\n",
        "y = Trend x Seasonality x Residual (Multiplicative)"
      ],
      "metadata": {
        "id": "rKeg_S3cCTBu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Datetime data manipulation\n",
        "df_daily_seas = df_daily.copy()\n"
      ],
      "metadata": {
        "id": "kHN2C6GKeuPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seasonal Decomposition for One Stocks\n"
      ],
      "metadata": {
        "id": "ijbMHWp-DVX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract Decomposition Value for each Stock\n",
        "seasonality_dict = {}\n",
        "trend_dict = {}\n",
        "\n",
        "for ts in df_daily_seas.columns:\n",
        "    decompositions = sm.tsa.seasonal_decompose(df_daily_seas[ts].fillna(method='ffill'),period=12)\n",
        "    # Store the results back\n",
        "    seasonality_dict[ts] = decompositions.seasonal\n",
        "    trend_dict[ts] = decompositions.trend"
      ],
      "metadata": {
        "id": "CeUHWBxGewDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seasonality Plot\n"
      ],
      "metadata": {
        "id": "dWxNCSA6frBF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trend Plot\n"
      ],
      "metadata": {
        "id": "CLNb--htvTom"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}